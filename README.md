# Desafios Code Elevate

## *Objetivo:*
  Nesse reposit√≥rio, vamos desenvolver 2 projetos solicitados nos desafios da esteira **Code Elevate**.
  
  Os desafios ser√£o separados em pastas para melhor visualiza√ß√£o dos c√≥digos. Os resultados ser√£o centralizados em um banco de dados DuckDB para todos os projetos.
  
  Arquivos originais que ser√£o consumidos, estar√£o na pasta raiz do projeto.

  - **Tecnologias utilizadas:**
  - *Python*
  - *Pyspark*
  - *Kafka*
  - *DuckDB*
  - *Docker*
  - *AirFlow*

### 1 - *Di√°rio de bordo*

#### üìå Objetivo

O projeto Di√°rio de Bordo tem como objetivo processar e armazenar informa√ß√µes sobre registros operacionais de transportes, garantindo a integridade e qualidade dos dados para an√°lise. O fluxo de dados segue os seguintes passos:

**Ingest√£o de Dados**: leitura de arquivos CSV e armazenamento no DuckDB.
**Processamento de Dados**: aplica√ß√£o de transforma√ß√µes usando PySpark.

#### üîß Tecnologias Utilizadas

- Python
- PySpark
- DuckDB
- Docker (containeriza√ß√£o)

#### Configura√ß√£o do Ambiente e Execu√ß√£o
       Subir o ambiente com Docker
       DuckDB e depend√™ncias, s√£o executados via Docker Compose.
   
       Rodar o processo de Ingest√£o de Dados
       O script **ingest_data.py** l√™ os dados do CSV e armazena no DuckDB.
   
       Executar o Processamento de Dados
       O script **process_data.py** realiza transforma√ß√µes nos dados usando PySpark.
   
       Validar os Dados no DuckDB
       Verifica a estrutura e integridade dos dados no banco.
       
### 2 - *Monitoramento de sensores IoT*

#### üìå Objetivo

Este projeto tem como objetivo criar um sistema de monitoramento de sensores IoT, utilizando Apache Kafka para transmiss√£o de dados em tempo real e DuckDB para armazenamento e an√°lise. O fluxo de dados segue os seguintes passos:

- **Producer**: gera dados simulados de sensores e os envia para um t√≥pico no Kafka.
- **Kafka**: gerencia e distribui os dados.
- **Consumer**: recebe os dados do t√≥pico Kafka e os armazena no banco de dados DuckDB.
- **Airflow** *(em desenvolvimento)* ser√° respons√°vel por orquestrar e monitorar o fluxo de dados.
- **Docker**: ser√° utilizado para empacotar e facilitar a execu√ß√£o do projeto.

#### üîß Tecnologias Utilizadas

- Python
- Apache Kafka
- DuckDB
- Airflow (orquestra√ß√£o - em desenvolvimento)
- Docker (containeriza√ß√£o)

####  Configura√ß√£o do Ambiente e execu√ß√£o
        Subir o Kafka com Docker
        O Kafka e o Zookeeper s√£o executados via Docker Compose.
    
        Criar o T√≥pico Kafka
        Ap√≥s iniciar o Kafka, crie um t√≥pico chamado iot_sensors:
    
        Rodar o Producer
        O Producer gera dados de sensores simulados e os envia para o Kafka.


# **Guia de Execu√ß√£o**

Todos os componentes do projeto s√£o executados dentro de containers Docker.

---

## **Configura√ß√£o do Ambiente**

### **Instale o Docker e o Docker Compose**
Se ainda n√£o tiver instalado, siga as instru√ß√µes originais:
- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### **Clone este reposit√≥rio**
```bash
git clone https://github.com/seu-repositorio.git
cd DesafiosCodeElevate
```

---

## **Como Executar os Containers**

### **Construir e iniciar os containers**
```bash
docker-compose up --build -d
```
Isso iniciar√° os containers:
- `app`: Container principal onde os scripts Python ser√£o executados.
- `kafka`: Servidor Kafka.
- `zookeeper`: Necess√°rio para o Kafka funcionar.

### **Verificar se os containers est√£o rodando**
```bash
docker ps
```
Se tudo estiver correto, os containers ser√£o listados.

---

## **Executar os Scripts do Projeto Transportes**

### **Acessar o aplicativo `app`**
```bash
docker exec -it desafioscodeelevate-app-1 bash
```

### **Rodar a ingest√£o de dados**
```bash
python /app/diario_de_bordo/ingest_data.py
```

### **Processar os dados**
```bash
python /app/diario_de_bordo/process_data.py
```

---

## **Executar o Projeto Sensores IoT**

### **Iniciar o Producer**
```bash
python /app/sensores_iot/producer.py
```

### **Iniciar o Consumer**
```bash
python /app/sensores_iot/consumer.py
```

---

## **Verificar os Dados no DuckDB**

### **Entrar no Python via container**
```bash
python
```

### **Listar as tabelas**
```python
import duckdb
con = duckdb.connect("/app/db_desafios.duckdb")
print(con.execute("SELECT table_name FROM information_schema.tables").fetchall())
```

### **Consultar os dados**
```python
print(con.execute("SELECT * FROM sensor_monitor.b_sensores_iot LIMIT 10").fetchall())
con.close()
```

Para sair do Python, digite `exit()`.

---

## **Parar os Containers**
Se precisar interromper todos os containers:
```bash
docker-compose down
```

---



